{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with NLTK\n",
    "\n",
    "## Introduction\n",
    "Natural Language Processing (NLP) is a field of Artificial Intelligence focused on enabling machines to understand, interpret, and generate human language. This notebook introduces NLP concepts using the Natural Language Toolkit (NLTK), one of Python's most popular NLP libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Basics of NLTK\n",
    "### Installation and Setup\n",
    "Install the NLTK library and download the required datasets.\n",
    "```python\n",
    "# Install NLTK\n",
    "!pip install nltk\n",
    "\n",
    "# Import and download NLTK datasets\n",
    "import nltk\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features of NLTK\n",
    "- Text Preprocessing - Tokenization, stemming, lemmatization, etc.\n",
    "    - Tokenization - Breaking text into words, sentences, etc.\n",
    "    - Stemming - Reducing words to their root form.\n",
    "    - Lemmatization - Reducing words to their base form.\n",
    "- Text Analysis - POS tagging, parsing, and semantic analysis.\n",
    "    - POS Tagging - Assigning parts of speech to words.\n",
    "    - Parsing - Analyzing the grammatical structure of sentences.\n",
    "    - Semantic Analysis - Understanding the meaning of words.\n",
    "- Applications - Sentiment analysis, language modeling, etc.\n",
    "    - Sentiment Analysis - Determining the sentiment of text.\n",
    "    - Language Modeling - Predicting the next word in a sentence.\n",
    "    - Named Entity Recognition - Identifying named entities in text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic NLP Tasks with NLTK**\n",
    "#### **Tokenization**\n",
    "Tokenization is the process of breaking text into words or sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['NLTK', 'makes', 'it', 'simple', 'to', 'process', 'text', 'data', '.', 'Let', \"'s\", 'explore', 'its', 'features', '!']\n",
      "Sentences: ['NLTK makes it simple to process text data.', \"Let's explore its features!\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Example text\n",
    "text = \"NLTK makes it simple to process text data. Let's explore its features!\"\n",
    "\n",
    "# Word Tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"Words:\", words)\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentences:\", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stemming**\n",
    "Stemming reduces words to their root forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'runner', 'easili', 'quickli']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Example words\n",
    "words = [\"running\", \"runner\", \"easily\", \"quickly\"]\n",
    "\n",
    "# Apply stemming\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "print(\"Stemmed Words:\", stems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Semantic Analysis (Synonyms and Antonyms)**\n",
    "Semantic analysis deals with understanding the meaning of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: {'happy', 'well-chosen', 'glad', 'felicitous'}\n",
      "Antonyms: {'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Synonyms and Antonyms of 'happy'\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"happy\"):\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.append(lemma.name())\n",
    "        if lemma.antonyms():\n",
    "            antonyms.append(lemma.antonyms()[0].name())\n",
    "\n",
    "print(\"Synonyms:\", set(synonyms))\n",
    "print(\"Antonyms:\", set(antonyms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment Analysis**\n",
    "#### **Preprocessing Text for Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['absolutely', 'love', 'using', 'NLTK', 'natural', 'language', 'processing', '.', \"'s\", 'amazing', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Example text\n",
    "text = \"I absolutely love using NLTK for natural language processing. It's amazing!\"\n",
    "\n",
    "# Remove Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = word_tokenize(text)\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "print(\"Filtered Words:\", filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sentiment Analysis with NLTK's SentimentIntensityAnalyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sreeh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: {'neg': 0.0, 'neu': 0.387, 'pos': 0.613, 'compound': 0.9019}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example text\n",
    "text = \"I absolutely love using NLTK for natural language processing. It's amazing!\"\n",
    "\n",
    "# Analyze sentiment\n",
    "sentiment = sia.polarity_scores(text)\n",
    "print(\"Sentiment Analysis:\", sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "npl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
